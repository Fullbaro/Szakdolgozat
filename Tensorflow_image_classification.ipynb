{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJ3WWZg8q0n2",
        "outputId": "7c7995e0-4f9d-48d3-c237-900d889f0405"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.0\n",
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "# Imports\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, auc, roc_curve\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import normalize\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import itertools \n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import shutil\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "print(tf.__version__)\n",
        "if device_name != '/device:GPU:0':\n",
        "  print('GPU device not found')\n",
        "else:\n",
        "  print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YbsbOWojqwZQ",
        "outputId": "7a220d26-870f-4ed9-e5d8-ae3b53100385"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Connect to google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-QC0oJnrrDLq"
      },
      "outputs": [],
      "source": [
        "# Dataset restore\n",
        "!rm -r /content/drive/MyDrive/Egyetem/dataset\n",
        "!unzip /content/drive/MyDrive/Egyetem/dataset7.0.zip -d /content/drive/MyDrive/Egyetem/\n",
        "\n",
        "# dataset \n",
        "#   |\n",
        "#   |- missing\n",
        "#   |     |- img.jpg\n",
        "#   |     |- ...\n",
        "#   |- present\n",
        "#   .      |- img.jpg\n",
        "#   .      |- ...\n",
        "#   .      .\n",
        "#          .\n",
        "#          ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jEIOx7C1TyQj"
      },
      "outputs": [],
      "source": [
        "for f in os.listdir(\"/content/drive/MyDrive/Egyetem/dataset\"):\n",
        "  print(f, len(os.listdir(\"/content/drive/MyDrive/Egyetem/dataset/\"+f)), \"db\")  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O7yc0mP9n-tM"
      },
      "outputs": [],
      "source": [
        "# OPTIONAL!\n",
        "def augment_images(path, num):\n",
        "  i=0\n",
        "  for img in os.listdir(path):\n",
        "    if \".jpg\" in img:\n",
        "      i = i + 1\n",
        "      if i > 15:\n",
        "        break\n",
        "      # Initialising the ImageDataGenerator class.\n",
        "      # We will pass in the augmentation parameters in the constructor.\n",
        "      datagen = ImageDataGenerator(            \n",
        "            horizontal_flip = True,\n",
        "            brightness_range = (0.5, 1.5))\n",
        "          \n",
        "      # Loading a sample image \n",
        "      img = load_img(os.path.join(path,img)) \n",
        "      # Converting the input sample image to an array\n",
        "      x = img_to_array(img)\n",
        "      # Reshaping the input image\n",
        "      x = x.reshape((1, ) + x.shape) \n",
        "      \n",
        "      # Generating and saving 5 augmented samples \n",
        "      # using the above defined parameters. \n",
        "      i = 0\n",
        "      for batch in datagen.flow(x, batch_size = 1,\n",
        "                                save_to_dir = path, \n",
        "                                save_prefix ='image', save_format ='jpg'):\n",
        "          i += 1\n",
        "          if i > num:\n",
        "              break\n",
        "\n",
        "augment_images(\"/content/drive/MyDrive/Egyetem/dataset/missing\", 5)\n",
        "print(\"Missing Done\")\n",
        "augment_images(\"/content/drive/MyDrive/Egyetem/dataset/present\", 5)\n",
        "print(\"Present Done\")\n",
        "augment_images(\"/content/drive/MyDrive/Egyetem/dataset/uncertain\", 5)\n",
        "print(\"Uncertain Done\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p996ViPFUAjX"
      },
      "outputs": [],
      "source": [
        "for f in os.listdir(\"/content/drive/MyDrive/Egyetem/dataset\"):\n",
        "  print(f, len(os.listdir(\"/content/drive/MyDrive/Egyetem/dataset/\"+f)))  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NfQPklQ9rphy"
      },
      "outputs": [],
      "source": [
        "# Defive valieables\n",
        "img_size = 56\n",
        "class_names = [\"missing\", \"present\", \"uncertain\"] # Class folder names!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WNGIa3F3rY_M"
      },
      "outputs": [],
      "source": [
        "# Create dataset\n",
        "\n",
        "def create_dataset(image_directory):\n",
        "  dataset = [] \n",
        "  label = []\n",
        "  for folder in os.listdir(image_directory):\n",
        "    images = os.listdir(image_directory + '/'+ folder)\n",
        "    for i, image_name in enumerate(images):      \n",
        "        if (image_name.split('.')[1] == 'jpg'): # Whatch out for file names and formats!\n",
        "            image = cv2.imread(image_directory + '/' +folder+ '/' + image_name)\n",
        "            image = Image.fromarray(image, 'RGB')\n",
        "            image = image.resize((img_size, img_size)) \n",
        "            image = np.flip(image, axis=-1) # Fix colors  \n",
        "            dataset.append(np.array(image).astype('float32') / 255.0)\n",
        "            label.append(class_names.index(folder))            \n",
        "\n",
        "  return np.array(dataset), np.array(label)\n",
        "\n",
        "\n",
        "dataset, label = create_dataset('/content/drive/MyDrive/Egyetem/dataset/')\n",
        "print(\"Dataset size is \", dataset.shape)\n",
        "print(\"Label size is \", label.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c2suEmCLRDSJ"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "k = list(Counter(label).keys())\n",
        "v = list(Counter(label).values())\n",
        "\n",
        "for i in k:\n",
        "  print(class_names[i]+\":\", v[i],\"db\") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hpI0AfO0sBA7"
      },
      "outputs": [],
      "source": [
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(dataset, label, test_size = 0.2)#, random_state = 0)\n",
        "print(\"Train size is \", X_train.shape)\n",
        "print(\"Test size is \", X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B93jl4cjwIVl"
      },
      "outputs": [],
      "source": [
        "# Train images preview\n",
        "def preview(X_train, y_train):\n",
        "  plt.figure(figsize=(10,10))\n",
        "  for i in range(25):\n",
        "      plt.subplot(5,5,i+1)\n",
        "      plt.xticks([])\n",
        "      plt.yticks([])\n",
        "      plt.grid(False)\n",
        "      plt.imshow(X_train[i], cmap=plt.cm.binary)\n",
        "      plt.xlabel(class_names[y_train[i]])\n",
        "  plt.show()\n",
        "\n",
        "preview(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "db4QcPdbt82c"
      },
      "outputs": [],
      "source": [
        "# Define the model\n",
        "def create_model():\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Conv2D(32, (3, 3), padding='same', input_shape=(img_size, img_size, 3)))\n",
        "  model.add(Activation('relu'))  \n",
        "  model.add(Conv2D(32, (3, 3)))\n",
        "  model.add(Activation('relu'))  \n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Conv2D(64, (3, 3)))\n",
        "  model.add(Activation('relu'))  \n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Conv2D(64, (3, 3)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(512))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.25))\n",
        "  model.add(Dense(3))\n",
        "  model.add(Activation('softmax'))\n",
        "\n",
        "  #model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['accuracy'])  \n",
        "  model.compile(optimizer='SGD', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    \n",
        "  return model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model = create_model()\n",
        "\n",
        "print(model.summary())\n",
        "print(\"Layer count:\", len(model.layers))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yz2hz132zsMB"
      },
      "outputs": [],
      "source": [
        "# Callbacks\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(\"/content/drive/MyDrive/Egyetem/checkpoints\", save_best_only=True)\n",
        "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5) # Ha 5 epoch alatt nem csökken a veszteség, leáll\n",
        "print_batch_callback = tf.keras.callbacks.LambdaCallback(\n",
        "    on_epoch_end=lambda a,b: print(\"\\n\", str((int(a)+1))+\". Epoch done.\", f\"Loss: {b['loss']}, Accuracy: {b['accuracy']}, Val_loss: {b['val_loss']}, Val_accuracy: {b['val_accuracy']}\", \"\\n\")\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zp2H-VMGvWF3"
      },
      "outputs": [],
      "source": [
        "# Train model\n",
        "def train_model(model):\n",
        "  return model.fit(\n",
        "                      X_train, \n",
        "                      y_train, \n",
        "                      batch_size = 16,\n",
        "                      verbose = 1, \n",
        "                      epochs = 100, # Stop early miatt úgyis kisebb!\n",
        "                      validation_data=(X_test, y_test),\n",
        "                      validation_split=0.2,    \n",
        "                      callbacks = [checkpoint, print_batch_callback, stop_early],#\n",
        "                      shuffle = True # False\n",
        "                    )\n",
        "  \n",
        "history = train_model(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eydFF--Owx9x"
      },
      "outputs": [],
      "source": [
        "# Show train history\n",
        "def plot_train_history(result):\n",
        "    plt.figure(1)      \n",
        "    plt.plot(result.history['accuracy'])              \n",
        "    plt.plot(result.history['val_accuracy'])          \n",
        "    plt.title('Model accuracy')  \n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Valid'], loc='upper left')      \n",
        "    plt.show()    \n",
        "    \n",
        "    plt.plot(result.history['loss'])      \n",
        "    plt.plot(result.history['val_loss'])      \n",
        "    plt.title('Model loss')  \n",
        "    plt.ylabel('Loss') \n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Valid'], loc='upper left')  \n",
        "    plt.show()   \n",
        "    \n",
        "plot_train_history(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nbWriFgLxtVP"
      },
      "outputs": [],
      "source": [
        "# Evaluate model\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)\n",
        "print('\\nTest accuracy:', test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eBHLbcL19u32"
      },
      "outputs": [],
      "source": [
        "# Save model\n",
        "model.save('/content/drive/MyDrive/Egyetem/model_new.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6yAtxYzuhHm1"
      },
      "outputs": [],
      "source": [
        "# Load model\n",
        "model = tf.keras.models.load_model('/content/drive/MyDrive/Egyetem/model_new.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vIB5o3dax4y6"
      },
      "outputs": [],
      "source": [
        "# Show confusion matrix\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')    \n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "            horizontalalignment=\"center\",\n",
        "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "\n",
        "\n",
        "\n",
        "pred = model.predict(x=X_test, steps=len(X_test), verbose=0)\n",
        "predictions = []\n",
        "for i in pred:    \n",
        "  predictions.append(np.argmax(i))\n",
        "\n",
        "cm = confusion_matrix(y_true=y_test, y_pred=predictions)\n",
        "plot_confusion_matrix(cm=cm, classes=class_names, title='Confusion Matrix')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tWUAcBHk44QJ"
      },
      "outputs": [],
      "source": [
        "def plot_image(i, predictions_array, true_label, img):\n",
        "  true_label, img = true_label[i], img[i]\n",
        "  plt.grid(False)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "\n",
        "  plt.imshow(img, cmap=plt.cm.binary)\n",
        "\n",
        "  \n",
        "\n",
        "  predicted_label = np.argmax(predictions_array)\n",
        "  if true_label == predicted_label:\n",
        "    color = 'blue'    \n",
        "  else:\n",
        "    color = 'red' \n",
        "    print(predictions_array, np.argmax(predictions_array), predictions_array[np.argmax(predictions_array)]) \n",
        "\n",
        "  \n",
        "\n",
        "  plt.xlabel(\"{} {}% ({})\".format(class_names[predicted_label],                                \n",
        "                                max(predictions_array)*100  ,\n",
        "                                class_names[true_label]),\n",
        "                                color=color)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mAP_SzpI48EE"
      },
      "outputs": [],
      "source": [
        "# Visualize predictions\n",
        "predictions = model.predict(X_test)\n",
        "num_rows = 5\n",
        "num_cols = 4\n",
        "num_images = num_rows*num_cols\n",
        "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
        "for i in range(num_images):\n",
        "  plt.subplot(num_rows, num_cols, i+1)\n",
        "  plot_image(i, predictions[i], y_test, X_test)  \n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LrUPTew6IP7U"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt \n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
        "\n",
        "target= class_names\n",
        "\n",
        "# set plot figure size\n",
        "fig, c_ax = plt.subplots(1,1, figsize = (12, 8))\n",
        "\n",
        "# function for scoring roc auc score for multi-class\n",
        "def multiclass_roc_auc_score(y_test, y_pred, average=\"macro\"):\n",
        "    pp = []\n",
        "    for p in y_pred:\n",
        "      pp.append(np.argmax(p))\n",
        "    \n",
        "    y_pred = pp\n",
        "    \n",
        "    lb = LabelBinarizer()\n",
        "    lb.fit(y_test)\n",
        "    y_test = lb.transform(y_test)\n",
        "    y_pred = lb.transform(y_pred)\n",
        "\n",
        "    for (idx, c_label) in enumerate(target):\n",
        "        fpr, tpr, thresholds = roc_curve(y_test[:,idx].astype(int), y_pred[:,idx])\n",
        "        c_ax.plot(fpr, tpr, label = '%s (AUC:%0.2f)'  % (c_label, auc(fpr, tpr)))\n",
        "    c_ax.plot(fpr, fpr, 'b-', label = 'Random Guessing')\n",
        "    return roc_auc_score(y_test, y_pred, average=average)\n",
        "\n",
        "\n",
        "score = multiclass_roc_auc_score(y_test, predictions)\n",
        "\n",
        "c_ax.legend()\n",
        "c_ax.set_xlabel('False Positive Rate')\n",
        "c_ax.title.set_text('ROC AUC score: '+str(score))\n",
        "c_ax.set_ylabel('True Positive Rate')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "from tensorflow.keras.models import Model\n",
        "from numpy import expand_dims\n",
        "\n",
        "ixs = [2, 5, 9]\n",
        "outputs = [model.layers[i].output for i in ixs]\n",
        "model = Model(inputs=model.inputs, outputs=outputs)\n",
        "# load the image with the required shape\n",
        "img = load_img('/content/drive/MyDrive/Egyetem/dataset/present/20220311113736806578.jpg', target_size=(img_size, img_size))\n",
        "# convert the image to an array\n",
        "img = img_to_array(img)\n",
        "# expand dimensions so that it represents a single 'sample'\n",
        "img = expand_dims(img, axis=0)\n",
        "# prepare the image (e.g. scale pixel values for the vgg)\n",
        "img = preprocess_input(img)\n",
        "# get feature map for first hidden layer\n",
        "feature_maps = model.predict(img)\n",
        "\n",
        "square = 4\n",
        "for fmap in feature_maps:\n",
        "\t# plot all 64 maps in an 8x8 squares\n",
        "\tix = 1\n",
        "\tfor _ in range(square):\n",
        "\t\tfor _ in range(square):\n",
        "\t\t\t# specify subplot and turn of axis\n",
        "\t\t\tax = plt.subplot(square, square, ix)\n",
        "\t\t\tax.set_xticks([])\n",
        "\t\t\tax.set_yticks([])\n",
        "\t\t\t# plot filter channel in grayscale\n",
        "\t\t\tplt.imshow(fmap[0, :, :, ix-1], cmap='gray')\n",
        "\t\t\tix += 1\n",
        "\t# show the figure\n",
        "\tplt.show()"
      ],
      "metadata": {
        "id": "gHpOpGhABEgl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kMHNydwvJLo5"
      },
      "outputs": [],
      "source": [
        "#Convert rmsprop optimalized model to tflite\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT] #Uses default optimization strategy to reduce the model size\n",
        "tflite_model = converter.convert()\n",
        "open(\"/content/drive/MyDrive/Egyetem/model_new.tflite\", \"wb\").write(tflite_model)\n",
        "tflite_size = os.path.getsize(\"/content/drive/MyDrive/Egyetem/model_new.tflite\")/1048576  #Convert to MB\n",
        "print(\"Tflite Model size: \", tflite_size, \"MB\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert SGD optimalized model to tflite\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.target_spec.supported_types = [tf.float32]\n",
        "converter.inference_input_type = tf.float32\n",
        "converter.inference_output_type = tf.float32\n",
        "\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "open(\"/content/drive/MyDrive/Egyetem/model_new.tflite\", \"wb\").write(tflite_model)\n",
        "tflite_size = os.path.getsize(\"/content/drive/MyDrive/Egyetem/model_new.tflite\")/1048576  #Convert to MB\n",
        "print(\"Tflite Model size: \", tflite_size, \"MB\")"
      ],
      "metadata": {
        "id": "Jk06P9cX3AGM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OALSkO3dJYAz"
      },
      "source": [
        "\n",
        "\n",
        "## **Tensorflow Lite model usage**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dIFvIAl6J2bE"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "from time import time\n",
        "from matplotlib import pyplot as plt\n",
        "import os\n",
        "import random\n",
        "from tensorflow.keras.utils import normalize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ClbmJkIMJpDu"
      },
      "outputs": [],
      "source": [
        "# Image loader\n",
        "def load_image(path):\n",
        "  image = load_img(path, target_size=(img_size, img_size))\n",
        "  image = (img_to_array(image)).astype('float32') / 255.0\n",
        "  image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))      \n",
        "  return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q4-E4fCnJ9V5"
      },
      "outputs": [],
      "source": [
        "# Returns random image from  folder\n",
        "def rand_image():\n",
        "  i = random.choice(os.listdir(\"/content/drive/MyDrive/Egyetem/real\"))\n",
        "  image = load_image(\"/content/drive/MyDrive/Egyetem/real/\"+i)    \n",
        "  return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aTI43cN1Kpdb"
      },
      "outputs": [],
      "source": [
        "tflite_model_path = \"/content/drive/MyDrive/Egyetem/model_new.tflite\"\n",
        "\n",
        "# Load the TFLite model and allocate tensors.\n",
        "interpreter = tf.lite.Interpreter(model_path=tflite_model_path)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Get input and output tensors.\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z-Za3tITLS4z"
      },
      "outputs": [],
      "source": [
        "# Load image\n",
        "input_data = rand_image() # Random igame from folder\n",
        "#input_data = load_image(\"/content/drive/MyDrive/Egyetem/t1.jpg\") # One exact image\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(input_data[0])  \n",
        "plt.grid(False)\n",
        "plt.show()\n",
        "\n",
        "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
        "\n",
        "time_before=time()\n",
        "interpreter.invoke()\n",
        "time_after=time()\n",
        "total_tflite_time = time_after - time_before\n",
        "\n",
        "output_data_tflite = interpreter.get_tensor(output_details[0]['index'])\n",
        "\n",
        "print(\"Sum\", np.sum(output_data_tflite[0]))\n",
        "print(\"Prediction:\", output_data_tflite[0],\n",
        "      max(output_data_tflite[0])*100,\n",
        "      class_names[np.argmax(output_data_tflite[0])])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sXlcx9dleh0j"
      },
      "outputs": [],
      "source": [
        "# Evaulate lite model\n",
        "good = 0\n",
        "bad = 0\n",
        "counter = 0\n",
        "for img in X_test:  \n",
        "  img = img.reshape((1, img.shape[0], img.shape[1], img.shape[2]))    \n",
        "  interpreter.set_tensor(input_details[0]['index'], img)  \n",
        "  interpreter.invoke()    \n",
        "  output_data_tflite = interpreter.get_tensor(output_details[0]['index'])\n",
        "  result = np.argmax(output_data_tflite[0])\n",
        "\n",
        "  #print(\"Result:\", result)\n",
        "  if result == y_test[counter]:    \n",
        "    good += 1\n",
        "  else:\n",
        "    bad += 1\n",
        "    # Show false predicted images\n",
        "    plt.figure()\n",
        "    plt.imshow(img[0])  \n",
        "    plt.grid(False)\n",
        "    plt.show()\n",
        "\n",
        "  counter += 1\n",
        "\n",
        "print(\"Result accuracy:\", good/(good+bad))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Tensorflow FINAL with uncertain.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}